<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="stylesheet" href="style.css">
    <link
        href="http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800"
        rel="stylesheet" type="text/css">
</head>

<body>
    <h1>Development Bot</h1>
    <iframe width="640" height="480"
        src="http://localhost:5040/7MkVBzx7pD46100623816959lsymJNpl/bot/7MLDQDqtDKWz112608574869DyPYHrIZ?display_header=false&history_retention=false"
        frameborder="0"></iframe>

    <script>
        let recorder;
        let socket;
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const output = document.getElementById('output');
        let recordedChunks = []; // Store actual Blob parts

        // Audio analysis variables
        let audioContext;
        let analyser;
        let silenceDetectionActive = false;
        const silenceThreshold = 0.06; // Adjust based on testing
        const maxSilenceDuration = 3000; // milliseconds
        let silenceStart;

        async function mergeBlobsToBase64(blobArray, mimeType = 'audio/webm') {
            // 1. Merge all Blobs into a single Blob
            const mergedBlob = new Blob(blobArray, { type: mimeType });

            // 2. Convert Blob to Base64
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onloadend = () => {
                    // Extract Base64 part (remove data:audio/webm;base64, prefix)
                    const base64String = reader.result.split(',')[1];
                    resolve(base64String);
                };
                reader.onerror = reject;
                reader.readAsDataURL(mergedBlob);
            });
        }

        startBtn.onclick = async () => {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            recorder = new MediaRecorder(stream);
            recordedChunks = [];

            // Initialize audio context and analyzer
            audioContext = new AudioContext();
            analyser = audioContext.createAnalyser();
            const microphone = audioContext.createMediaStreamSource(stream);
            microphone.connect(analyser);
            analyser.fftSize = 2048;

            // Connect to WebSocket
            socket = new WebSocket('ws://localhost:3000');

            socket.onmessage = event => {
                const base64String = event.data;
                const binaryString = atob(base64String);
                const len = binaryString.length;
                const bytes = new Uint8Array(len);

                for (let i = 0; i < len; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }

                const blob = new Blob([bytes], { type: 'audio/webm' });
                const audioURL = URL.createObjectURL(blob);
                const audio = new Audio(audioURL);
                audio.play();
            };

            recorder.ondataavailable = async event => {
                console.log("Hello")
                if (event.data.size > 0) {
                    recordedChunks.push(event.data); // Save raw blob parts
                    const base64Chunk = await blobToBase64(event.data);
                    output.value += base64Chunk.slice(0, 30) + '...\n';

                    if (socket.readyState === WebSocket.OPEN) {
                        socket.send(base64Chunk);
                    }
                }
            };

            // Start silence detection
            silenceDetectionActive = true;
            silenceStart = performance.now();
            checkSilence();

            recorder.start(); // Timeslice = 1s
            startBtn.disabled = true;
            stopBtn.disabled = false;
        };

        stopBtn.onclick = () => {
            stopRecording();
        };

        function stopRecording() {
            console.log("silence deteced!!!!")
            if (recorder && recorder.state !== 'inactive') {
                console.log("stopped recording", recorder)
                recorder.requestData();
            }
            if (socket) {
                socket.close();
            }

            // Close audio context if it exists
        }

        function blobToBase64(blob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onloadend = () => {
                    const base64data = reader.result.split(',')[1];
                    resolve(base64data);
                };
                reader.onerror = reject;
                reader.readAsDataURL(blob);
            });
        }

        function checkSilence() {
            if (!silenceDetectionActive) return;

            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteTimeDomainData(dataArray);

            let sum = 0;
            for (let i = 0; i < dataArray.length; i++) {
                const normalized = (dataArray[i] - 128) / 128;
                sum += normalized * normalized;
            }
            const volume = Math.sqrt(sum / dataArray.length);

            if (volume < silenceThreshold) {
                if (performance.now() - silenceStart > maxSilenceDuration) {
                    stopRecording();
                    mergeBlobsToBase64(recordedChunks)
                        .then(base64String => {
                            console.log("Full Base64 audio:", base64String);
                            // Use the Base64 string (e.g., send to server, store in DB, etc.)
                        })
                        .catch(error => {
                            console.error("Conversion failed:", error);
                        });
                    return;
                }
            } else {
                silenceStart = performance.now();
            }

            requestAnimationFrame(checkSilence);
        }

        function playAudio() {
            if (recordedChunks.length === 0) {
                console.warn("No audio recorded.");
                return;
            }

            // Combine all Blob chunks into one
            const fullBlob = new Blob(recordedChunks, { type: "audio/webm" });
            const audioURL = URL.createObjectURL(fullBlob);
            const audio = new Audio(audioURL);
            audio.play().catch(e => {
                console.error("Audio play failed:", e);
            });
        }

        const isValidJson = (text) => {
            try {
                JSON.parse(text);
                return true;
            } catch (e) {
                return false;
            }
        };

        window.addEventListener("message", function (event) {
            if (event?.data && isValidJson(event?.data)) {
                const eventData = JSON.parse(event.data)
                console.log(eventData);
            }
        });


    </script>
    <!-- <script src="https://bot.firmli.com/chat-widget/7NMyWegwGABd060419500067IqrFeDcN.js" defer></script> -->
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MW9ZRN5QDK"></script>
</body>

</html>